{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Capstone Project: Applying machine learning for temporomandibular disorders diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains all code developed to achive goals described in *proposal.pdf* and to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration\n",
    "\n",
    "Markdown resources:\n",
    "\n",
    ">**Note:** Description.\n",
    "\n",
    "**Bold**\n",
    "*italic*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display \n",
    "import visuals as vs\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from keras import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients dataset has 681 samples with 401 features each.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "try:\n",
    "    dataset = pd.read_csv(\"data/tmd_data.csv\")\n",
    "    dataset.head(10)\n",
    "    print(\"Patients dataset has {} samples with {} features each.\".format(*dataset.shape))\n",
    "except Exception as e:\n",
    "    s = str(e)\n",
    "    print(\"Dataset could not be loaded. Is the dataset missing?\", s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a first look to dataset. We are interested in knowing number, type, range of values and empty parameters in order to take further decissions about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column  Q1 has  2  different values of type  int64\n",
      "Column  Q2 has  2  different values of type  int64\n",
      "Column  Q3 has  2  different values of type  int64\n",
      "Column  Q4 has  2  different values of type  int64\n",
      "Column  Q5 has  2  different values of type  int64\n",
      "Column  Q6 has  2  different values of type  int64\n",
      "Column  Q7 has  2  different values of type  int64\n",
      "Column  Q8 has  2  different values of type  int64\n",
      "Column  Q9 has  2  different values of type  int64\n",
      "Column  Q10 has  7  different values of type  int64\n",
      "Column  Q11 has  2  different values of type  int64\n",
      "Column  Q12 has  2  different values of type  int64\n",
      "Column  Q13 has  2  different values of type  int64\n",
      "Column  Q14 has  2  different values of type  int64\n",
      "Column  Q15 has  2  different values of type  int64\n",
      "Column  Q16 has  2  different values of type  int64\n",
      "Column  Q17 has  2  different values of type  int64\n",
      "Column  Q18 has  2  different values of type  int64\n",
      "Column  Q19 has  7  different values of type  int64\n",
      "Column  Q20 has  2  different values of type  int64\n",
      "Column  Q21 has  2  different values of type  int64\n",
      "Column  Q22 has  2  different values of type  int64\n",
      "Column  Q23 has  2  different values of type  int64\n",
      "Column  Q24 has  2  different values of type  int64\n",
      "Column  Q25 has  2  different values of type  int64\n",
      "Column  Q26 has  2  different values of type  int64\n",
      "Column  Q27 has  2  different values of type  int64\n",
      "Column  Q28 has  2  different values of type  int64\n",
      "Column  Q29 has  2  different values of type  int64\n",
      "Column  Q30 has  2  different values of type  int64\n",
      "Column  Q31 has  2  different values of type  int64\n",
      "Column  Q32 has  2  different values of type  int64\n",
      "Column  Q33 has  2  different values of type  int64\n",
      "Column  Q34 has  2  different values of type  int64\n",
      "Column  Q35 has  2  different values of type  int64\n",
      "Column  Q36 has  2  different values of type  int64\n",
      "Column  Q37 has  2  different values of type  int64\n",
      "Column  Q38 has  2  different values of type  int64\n",
      "Column  Q39 has  2  different values of type  int64\n",
      "Column  Q40 has  2  different values of type  int64\n",
      "Column  Q41 has  2  different values of type  int64\n",
      "Column  Q42 has  2  different values of type  int64\n",
      "Column  Q43 has  2  different values of type  int64\n",
      "Column  Q44 has  2  different values of type  int64\n",
      "Column  Q45 has  2  different values of type  int64\n",
      "Column  Q46 has  2  different values of type  int64\n",
      "Column  Q47 has  2  different values of type  int64\n",
      "Column  Q48 has  2  different values of type  int64\n",
      "Column  Q49 has  6  different values of type  int64\n",
      "Column  Q50 has  4  different values of type  int64\n",
      "Column  Q51 has  7  different values of type  int64\n",
      "Column  Q52 has  2  different values of type  int64\n",
      "Column  Q53 has  2  different values of type  int64\n",
      "Column  Q54 has  2  different values of type  int64\n",
      "Column  Q55 has  2  different values of type  int64\n",
      "Column  Q56 has  2  different values of type  int64\n",
      "Column  Q57 has  2  different values of type  int64\n",
      "Column  Q58 has  2  different values of type  int64\n",
      "Column  Q59 has  2  different values of type  int64\n",
      "Column  Q60 has  2  different values of type  int64\n",
      "Column  Q61 has  2  different values of type  int64\n",
      "Column  Q62 has  2  different values of type  int64\n",
      "Column  Q63 has  2  different values of type  int64\n",
      "Column  Q64 has  2  different values of type  int64\n",
      "Column  Q65 has  2  different values of type  int64\n",
      "Column  Q66 has  2  different values of type  int64\n",
      "Column  Q67 has  2  different values of type  int64\n",
      "Column  Q68 has  2  different values of type  int64\n",
      "Column  Q69 has  2  different values of type  int64\n",
      "Column  Q70 has  2  different values of type  int64\n",
      "Column  Q71 has  2  different values of type  int64\n",
      "Column  Q72 has  2  different values of type  int64\n",
      "Column  Q73 has  2  different values of type  int64\n",
      "Column  Q74 has  1  different values of type  float64\n",
      "Column  Q75 has  2  different values of type  int64\n",
      "Column  Q76 has  1  different values of type  float64\n",
      "Column  Q77 has  2  different values of type  int64\n",
      "Column  Q78 has  1  different values of type  float64\n",
      "Column  Q79 has  2  different values of type  int64\n",
      "Column  Q80 has  1  different values of type  float64\n",
      "Column  Q81 has  2  different values of type  int64\n",
      "Column  Q82 has  1  different values of type  float64\n",
      "Column  Q83 has  2  different values of type  int64\n",
      "Column  Q84 has  1  different values of type  float64\n",
      "Column  Q85 has  2  different values of type  int64\n",
      "Column  Q86 has  1  different values of type  float64\n",
      "Column  Q87 has  2  different values of type  int64\n",
      "Column  Q88 has  1  different values of type  float64\n",
      "Column  Q89 has  2  different values of type  int64\n",
      "Column  Q90 has  1  different values of type  float64\n",
      "Column  Q91 has  2  different values of type  int64\n",
      "Column  Q92 has  1  different values of type  float64\n",
      "Column  Q93 has  2  different values of type  int64\n",
      "Column  Q94 has  1  different values of type  float64\n",
      "Column  Q95 has  2  different values of type  int64\n",
      "Column  Q96 has  1  different values of type  float64\n",
      "Column  Q97 has  2  different values of type  int64\n",
      "Column  Q98 has  2  different values of type  int64\n",
      "Column  Q99 has  2  different values of type  int64\n",
      "Column  Q100 has  1  different values of type  float64\n",
      "Column  Q101 has  1  different values of type  float64\n",
      "Column  Q102 has  1  different values of type  float64\n",
      "Column  Q103 has  3  different values of type  int64\n",
      "Column  Q104 has  3  different values of type  int64\n",
      "Column  Q105 has  4  different values of type  int64\n",
      "Column  Q106 has  3  different values of type  int64\n",
      "Column  Q107 has  6  different values of type  int64\n",
      "Column  Q108 has  6  different values of type  int64\n",
      "Column  Q109 has  2  different values of type  int64\n",
      "Column  Q110 has  2  different values of type  int64\n",
      "Column  Q111 has  2  different values of type  int64\n",
      "Column  Q112 has  2  different values of type  int64\n",
      "Column  Q113 has  2  different values of type  int64\n",
      "Column  Q114 has  47  different values of type  int64\n",
      "Column  Q115 has  41  different values of type  int64\n",
      "Column  Q116 has  36  different values of type  int64\n",
      "Column  Q117 has  2  different values of type  int64\n",
      "Column  Q118 has  2  different values of type  int64\n",
      "Column  Q119 has  2  different values of type  int64\n",
      "Column  Q120 has  2  different values of type  int64\n",
      "Column  Q121 has  2  different values of type  int64\n",
      "Column  Q122 has  2  different values of type  int64\n",
      "Column  Q123 has  2  different values of type  int64\n",
      "Column  Q124 has  2  different values of type  int64\n",
      "Column  Q125 has  2  different values of type  int64\n",
      "Column  Q126 has  2  different values of type  int64\n",
      "Column  Q127 has  2  different values of type  int64\n",
      "Column  Q128 has  2  different values of type  int64\n",
      "Column  Q129 has  2  different values of type  int64\n",
      "Column  Q130 has  2  different values of type  int64\n",
      "Column  Q131 has  1  different values of type  int64\n",
      "Column  Q132 has  2  different values of type  int64\n",
      "Column  Q133 has  1  different values of type  int64\n",
      "Column  Q134 has  2  different values of type  int64\n",
      "Column  Q135 has  1  different values of type  int64\n",
      "Column  Q136 has  2  different values of type  int64\n",
      "Column  Q137 has  1  different values of type  int64\n",
      "Column  Q138 has  2  different values of type  int64\n",
      "Column  Q139 has  2  different values of type  int64\n",
      "Column  Q140 has  2  different values of type  int64\n",
      "Column  Q141 has  2  different values of type  int64\n",
      "Column  Q142 has  2  different values of type  int64\n",
      "Column  Q143 has  2  different values of type  int64\n",
      "Column  Q144 has  2  different values of type  int64\n",
      "Column  Q145 has  2  different values of type  int64\n",
      "Column  Q146 has  2  different values of type  int64\n",
      "Column  Q147 has  2  different values of type  int64\n",
      "Column  Q148 has  2  different values of type  int64\n",
      "Column  Q149 has  2  different values of type  int64\n",
      "Column  Q150 has  2  different values of type  int64\n",
      "Column  Q151 has  2  different values of type  int64\n",
      "Column  Q152 has  1  different values of type  int64\n",
      "Column  Q153 has  2  different values of type  int64\n",
      "Column  Q154 has  1  different values of type  int64\n",
      "Column  Q155 has  2  different values of type  int64\n",
      "Column  Q156 has  1  different values of type  int64\n",
      "Column  Q157 has  2  different values of type  int64\n",
      "Column  Q158 has  1  different values of type  int64\n",
      "Column  Q159 has  2  different values of type  int64\n",
      "Column  Q160 has  12  different values of type  int64\n",
      "Column  Q161 has  12  different values of type  int64\n",
      "Column  Q162 has  10  different values of type  int64\n",
      "Column  Q163 has  2  different values of type  int64\n",
      "Column  Q164 has  2  different values of type  int64\n",
      "Column  Q165 has  2  different values of type  int64\n",
      "Column  Q166 has  2  different values of type  int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column  Q167 has  2  different values of type  int64\n",
      "Column  Q168 has  2  different values of type  int64\n",
      "Column  Q169 has  2  different values of type  int64\n",
      "Column  Q170 has  2  different values of type  int64\n",
      "Column  Q171 has  2  different values of type  int64\n",
      "Column  Q172 has  2  different values of type  int64\n",
      "Column  Q173 has  2  different values of type  int64\n",
      "Column  Q174 has  2  different values of type  int64\n",
      "Column  Q175 has  2  different values of type  int64\n",
      "Column  Q176 has  1  different values of type  int64\n",
      "Column  Q177 has  2  different values of type  int64\n",
      "Column  Q178 has  1  different values of type  int64\n",
      "Column  Q179 has  2  different values of type  int64\n",
      "Column  Q180 has  1  different values of type  int64\n",
      "Column  Q181 has  2  different values of type  int64\n",
      "Column  Q182 has  1  different values of type  int64\n",
      "Column  Q183 has  2  different values of type  int64\n",
      "Column  Q184 has  2  different values of type  int64\n",
      "Column  Q185 has  2  different values of type  int64\n",
      "Column  Q186 has  2  different values of type  int64\n",
      "Column  Q187 has  2  different values of type  int64\n",
      "Column  Q188 has  2  different values of type  int64\n",
      "Column  Q189 has  2  different values of type  int64\n",
      "Column  Q190 has  2  different values of type  int64\n",
      "Column  Q191 has  2  different values of type  int64\n",
      "Column  Q192 has  2  different values of type  int64\n",
      "Column  Q193 has  2  different values of type  int64\n",
      "Column  Q194 has  2  different values of type  int64\n",
      "Column  Q195 has  2  different values of type  int64\n",
      "Column  Q196 has  2  different values of type  int64\n",
      "Column  Q197 has  1  different values of type  int64\n",
      "Column  Q198 has  2  different values of type  int64\n",
      "Column  Q199 has  1  different values of type  int64\n",
      "Column  Q200 has  2  different values of type  int64\n",
      "Column  Q201 has  1  different values of type  int64\n",
      "Column  Q202 has  2  different values of type  int64\n",
      "Column  Q203 has  1  different values of type  int64\n",
      "Column  Q204 has  2  different values of type  int64\n",
      "Column  Q205 has  2  different values of type  int64\n",
      "Column  Q206 has  2  different values of type  int64\n",
      "Column  Q207 has  2  different values of type  int64\n",
      "Column  Q208 has  2  different values of type  int64\n",
      "Column  Q209 has  2  different values of type  int64\n",
      "Column  Q210 has  1  different values of type  int64\n",
      "Column  Q211 has  2  different values of type  int64\n",
      "Column  Q212 has  1  different values of type  int64\n",
      "Column  Q213 has  2  different values of type  int64\n",
      "Column  Q214 has  2  different values of type  int64\n",
      "Column  Q215 has  2  different values of type  int64\n",
      "Column  Q216 has  2  different values of type  int64\n",
      "Column  Q217 has  2  different values of type  int64\n",
      "Column  Q218 has  1  different values of type  int64\n",
      "Column  Q219 has  2  different values of type  int64\n",
      "Column  Q220 has  1  different values of type  int64\n",
      "Column  Q221 has  2  different values of type  int64\n",
      "Column  Q222 has  1  different values of type  int64\n",
      "Column  Q223 has  2  different values of type  int64\n",
      "Column  Q224 has  1  different values of type  int64\n",
      "Column  Q225 has  2  different values of type  int64\n",
      "Column  Q226 has  2  different values of type  int64\n",
      "Column  Q227 has  2  different values of type  int64\n",
      "Column  Q228 has  2  different values of type  int64\n",
      "Column  Q229 has  2  different values of type  int64\n",
      "Column  Q230 has  2  different values of type  int64\n",
      "Column  Q231 has  2  different values of type  int64\n",
      "Column  Q232 has  2  different values of type  int64\n",
      "Column  Q233 has  2  different values of type  int64\n",
      "Column  Q234 has  2  different values of type  int64\n",
      "Column  Q235 has  2  different values of type  int64\n",
      "Column  Q236 has  2  different values of type  int64\n",
      "Column  Q237 has  2  different values of type  int64\n",
      "Column  Q238 has  2  different values of type  int64\n",
      "Column  Q239 has  2  different values of type  int64\n",
      "Column  Q240 has  2  different values of type  int64\n",
      "Column  Q241 has  2  different values of type  int64\n",
      "Column  Q242 has  2  different values of type  int64\n",
      "Column  Q243 has  2  different values of type  int64\n",
      "Column  Q244 has  2  different values of type  int64\n",
      "Column  Q245 has  2  different values of type  int64\n",
      "Column  Q246 has  2  different values of type  int64\n",
      "Column  Q247 has  2  different values of type  int64\n",
      "Column  Q248 has  2  different values of type  int64\n",
      "Column  Q249 has  2  different values of type  int64\n",
      "Column  Q250 has  2  different values of type  int64\n",
      "Column  Q251 has  2  different values of type  int64\n",
      "Column  Q252 has  2  different values of type  int64\n",
      "Column  Q253 has  2  different values of type  int64\n",
      "Column  Q254 has  2  different values of type  int64\n",
      "Column  Q255 has  2  different values of type  int64\n",
      "Column  Q256 has  2  different values of type  int64\n",
      "Column  Q257 has  2  different values of type  int64\n",
      "Column  Q258 has  2  different values of type  int64\n",
      "Column  Q259 has  2  different values of type  int64\n",
      "Column  Q260 has  2  different values of type  int64\n",
      "Column  Q261 has  2  different values of type  int64\n",
      "Column  Q262 has  2  different values of type  int64\n",
      "Column  Q263 has  2  different values of type  int64\n",
      "Column  Q264 has  2  different values of type  int64\n",
      "Column  Q265 has  2  different values of type  int64\n",
      "Column  Q266 has  2  different values of type  int64\n",
      "Column  Q267 has  2  different values of type  int64\n",
      "Column  Q268 has  2  different values of type  int64\n",
      "Column  Q269 has  2  different values of type  int64\n",
      "Column  Q270 has  2  different values of type  int64\n",
      "Column  Q271 has  2  different values of type  int64\n",
      "Column  Q272 has  2  different values of type  int64\n",
      "Column  Q273 has  2  different values of type  int64\n",
      "Column  Q274 has  2  different values of type  int64\n",
      "Column  Q275 has  2  different values of type  int64\n",
      "Column  Q276 has  2  different values of type  int64\n",
      "Column  Q277 has  2  different values of type  int64\n",
      "Column  Q278 has  2  different values of type  int64\n",
      "Column  Q279 has  2  different values of type  int64\n",
      "Column  Q280 has  2  different values of type  int64\n",
      "Column  Q281 has  2  different values of type  int64\n",
      "Column  Q282 has  2  different values of type  int64\n",
      "Column  Q283 has  2  different values of type  int64\n",
      "Column  Q284 has  2  different values of type  int64\n",
      "Column  Q285 has  2  different values of type  int64\n",
      "Column  Q286 has  2  different values of type  int64\n",
      "Column  Q287 has  2  different values of type  int64\n",
      "Column  Q288 has  2  different values of type  int64\n",
      "Column  Q289 has  2  different values of type  int64\n",
      "Column  Q290 has  2  different values of type  int64\n",
      "Column  Q291 has  2  different values of type  int64\n",
      "Column  Q292 has  2  different values of type  int64\n",
      "Column  Q293 has  2  different values of type  int64\n",
      "Column  Q294 has  2  different values of type  int64\n",
      "Column  Q295 has  2  different values of type  int64\n",
      "Column  Q296 has  2  different values of type  int64\n",
      "Column  Q297 has  2  different values of type  int64\n",
      "Column  Q298 has  2  different values of type  int64\n",
      "Column  Q299 has  2  different values of type  int64\n",
      "Column  Q300 has  2  different values of type  int64\n",
      "Column  Q301 has  2  different values of type  int64\n",
      "Column  Q302 has  2  different values of type  int64\n",
      "Column  Q303 has  2  different values of type  int64\n",
      "Column  Q304 has  2  different values of type  int64\n",
      "Column  Q305 has  2  different values of type  int64\n",
      "Column  Q306 has  2  different values of type  int64\n",
      "Column  Q307 has  2  different values of type  int64\n",
      "Column  Q308 has  2  different values of type  int64\n",
      "Column  Q309 has  2  different values of type  int64\n",
      "Column  Q310 has  2  different values of type  int64\n",
      "Column  Q311 has  2  different values of type  int64\n",
      "Column  Q312 has  2  different values of type  int64\n",
      "Column  Q313 has  2  different values of type  int64\n",
      "Column  Q314 has  2  different values of type  int64\n",
      "Column  Q315 has  2  different values of type  int64\n",
      "Column  Q316 has  2  different values of type  int64\n",
      "Column  Q317 has  2  different values of type  int64\n",
      "Column  Q318 has  2  different values of type  int64\n",
      "Column  Q319 has  2  different values of type  int64\n",
      "Column  Q320 has  2  different values of type  int64\n",
      "Column  Q321 has  2  different values of type  int64\n",
      "Column  Q322 has  2  different values of type  int64\n",
      "Column  Q323 has  2  different values of type  int64\n",
      "Column  Q324 has  2  different values of type  int64\n",
      "Column  Q325 has  2  different values of type  int64\n",
      "Column  Q326 has  2  different values of type  int64\n",
      "Column  Q327 has  2  different values of type  int64\n",
      "Column  Q328 has  2  different values of type  int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column  Q329 has  2  different values of type  int64\n",
      "Column  Q330 has  2  different values of type  int64\n",
      "Column  Q331 has  2  different values of type  int64\n",
      "Column  Q332 has  2  different values of type  int64\n",
      "Column  Q333 has  2  different values of type  int64\n",
      "Column  Q334 has  2  different values of type  int64\n",
      "Column  Q335 has  2  different values of type  int64\n",
      "Column  Q336 has  2  different values of type  int64\n",
      "Column  Q337 has  2  different values of type  int64\n",
      "Column  Q338 has  2  different values of type  int64\n",
      "Column  Q339 has  2  different values of type  int64\n",
      "Column  Q340 has  2  different values of type  int64\n",
      "Column  Q341 has  2  different values of type  int64\n",
      "Column  Q342 has  2  different values of type  int64\n",
      "Column  Q343 has  2  different values of type  int64\n",
      "Column  Q344 has  2  different values of type  int64\n",
      "Column  Q345 has  2  different values of type  int64\n",
      "Column  Q346 has  2  different values of type  int64\n",
      "Column  Q347 has  2  different values of type  int64\n",
      "Column  Q348 has  2  different values of type  int64\n",
      "Column  Q349 has  1  different values of type  int64\n",
      "Column  Q350 has  1  different values of type  int64\n",
      "Column  Q351 has  2  different values of type  int64\n",
      "Column  Q352 has  1  different values of type  int64\n",
      "Column  Q353 has  1  different values of type  int64\n",
      "Column  Q354 has  2  different values of type  int64\n",
      "Column  Q355 has  1  different values of type  int64\n",
      "Column  Q356 has  1  different values of type  int64\n",
      "Column  Q357 has  2  different values of type  int64\n",
      "Column  Q358 has  1  different values of type  int64\n",
      "Column  Q359 has  1  different values of type  int64\n",
      "Column  Q360 has  2  different values of type  int64\n",
      "Column  Q361 has  2  different values of type  int64\n",
      "Column  Q362 has  1  different values of type  int64\n",
      "Column  Q363 has  2  different values of type  int64\n",
      "Column  Q364 has  2  different values of type  int64\n",
      "Column  Q365 has  1  different values of type  int64\n",
      "Column  Q366 has  2  different values of type  int64\n",
      "Column  Q367 has  2  different values of type  int64\n",
      "Column  Q368 has  1  different values of type  int64\n",
      "Column  Q369 has  2  different values of type  int64\n",
      "Column  Q370 has  2  different values of type  int64\n",
      "Column  Q371 has  1  different values of type  int64\n",
      "Column  Q372 has  2  different values of type  int64\n",
      "Column  Q373 has  2  different values of type  int64\n",
      "Column  Q374 has  2  different values of type  int64\n",
      "Column  Q375 has  2  different values of type  int64\n",
      "Column  Q376 has  2  different values of type  int64\n",
      "Column  Q377 has  2  different values of type  int64\n",
      "Column  Q378 has  2  different values of type  int64\n",
      "Column  Q379 has  2  different values of type  int64\n",
      "Column  Q380 has  2  different values of type  int64\n",
      "Column  Q381 has  2  different values of type  int64\n",
      "Column  Q382 has  2  different values of type  int64\n",
      "Column  Q383 has  2  different values of type  int64\n",
      "Column  Q384 has  2  different values of type  int64\n",
      "Column  Q385 has  2  different values of type  int64\n",
      "Column  Q386 has  2  different values of type  int64\n",
      "Column  Q387 has  2  different values of type  int64\n",
      "Column  Q388 has  2  different values of type  int64\n",
      "Column  Q389 has  2  different values of type  int64\n",
      "Column  Q390 has  2  different values of type  int64\n",
      "Column  Q391 has  2  different values of type  int64\n",
      "Column  Q392 has  2  different values of type  int64\n",
      "Column  Q393 has  2  different values of type  int64\n",
      "Column  Q394 has  2  different values of type  int64\n",
      "Column  Q395 has  2  different values of type  int64\n",
      "Column  Q396 has  2  different values of type  int64\n",
      "Column  Q397 has  2  different values of type  int64\n",
      "Column  Q398 has  2  different values of type  int64\n",
      "Column  Q399 has  2  different values of type  int64\n",
      "Column  Q400 has  2  different values of type  int64\n",
      "Column  Label has  11  different values of type  object\n"
     ]
    }
   ],
   "source": [
    "# All empty columns are going to be dropped out later\n",
    "null_columns=dataset.columns[dataset.isnull().all()]\n",
    "# One single value columns are good candidates to get rid off them\n",
    "one_value_params = []\n",
    "# Integer (non-boolean) values columns are likely to be regularized later\n",
    "int_value_params = []\n",
    "\n",
    "for i in range(0, len(dataset.columns)) :\n",
    "    column = dataset.columns[i]\n",
    "    print(\"Column \", column, 'has ', len(dataset[column].unique()),' different values of type ',dataset[column].dtype)\n",
    "    if len(dataset[column].unique()) == 1 : \n",
    "        one_value_params.append(column)\n",
    "    elif len(dataset[column].unique()) > 2 : \n",
    "        int_value_params.append(column)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q391</th>\n",
       "      <th>Q392</th>\n",
       "      <th>Q393</th>\n",
       "      <th>Q394</th>\n",
       "      <th>Q395</th>\n",
       "      <th>Q396</th>\n",
       "      <th>Q397</th>\n",
       "      <th>Q398</th>\n",
       "      <th>Q399</th>\n",
       "      <th>Q400</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>681.00000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>681.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.63583</td>\n",
       "      <td>0.349486</td>\n",
       "      <td>0.355360</td>\n",
       "      <td>0.555066</td>\n",
       "      <td>0.509545</td>\n",
       "      <td>0.538913</td>\n",
       "      <td>0.506608</td>\n",
       "      <td>0.475771</td>\n",
       "      <td>0.725404</td>\n",
       "      <td>3.809104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.646109</td>\n",
       "      <td>0.509545</td>\n",
       "      <td>0.484581</td>\n",
       "      <td>0.550661</td>\n",
       "      <td>0.618209</td>\n",
       "      <td>0.609398</td>\n",
       "      <td>0.534508</td>\n",
       "      <td>0.475771</td>\n",
       "      <td>0.248164</td>\n",
       "      <td>0.283407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.48155</td>\n",
       "      <td>0.477158</td>\n",
       "      <td>0.478974</td>\n",
       "      <td>0.497324</td>\n",
       "      <td>0.500276</td>\n",
       "      <td>0.498850</td>\n",
       "      <td>0.500324</td>\n",
       "      <td>0.499780</td>\n",
       "      <td>0.446639</td>\n",
       "      <td>1.945275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.478527</td>\n",
       "      <td>0.500276</td>\n",
       "      <td>0.500130</td>\n",
       "      <td>0.497792</td>\n",
       "      <td>0.486183</td>\n",
       "      <td>0.488244</td>\n",
       "      <td>0.499174</td>\n",
       "      <td>0.499780</td>\n",
       "      <td>0.432265</td>\n",
       "      <td>0.450983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Q1          Q2          Q3          Q4          Q5          Q6  \\\n",
       "count  681.00000  681.000000  681.000000  681.000000  681.000000  681.000000   \n",
       "mean     0.63583    0.349486    0.355360    0.555066    0.509545    0.538913   \n",
       "std      0.48155    0.477158    0.478974    0.497324    0.500276    0.498850   \n",
       "min      0.00000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.00000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      1.00000    0.000000    0.000000    1.000000    1.000000    1.000000   \n",
       "75%      1.00000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "max      1.00000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               Q7          Q8          Q9         Q10     ...            Q391  \\\n",
       "count  681.000000  681.000000  681.000000  681.000000     ...      681.000000   \n",
       "mean     0.506608    0.475771    0.725404    3.809104     ...        0.646109   \n",
       "std      0.500324    0.499780    0.446639    1.945275     ...        0.478527   \n",
       "min      0.000000    0.000000    0.000000    1.000000     ...        0.000000   \n",
       "25%      0.000000    0.000000    0.000000    2.000000     ...        0.000000   \n",
       "50%      1.000000    0.000000    1.000000    4.000000     ...        1.000000   \n",
       "75%      1.000000    1.000000    1.000000    6.000000     ...        1.000000   \n",
       "max      1.000000    1.000000    1.000000    7.000000     ...        1.000000   \n",
       "\n",
       "             Q392        Q393        Q394        Q395        Q396        Q397  \\\n",
       "count  681.000000  681.000000  681.000000  681.000000  681.000000  681.000000   \n",
       "mean     0.509545    0.484581    0.550661    0.618209    0.609398    0.534508   \n",
       "std      0.500276    0.500130    0.497792    0.486183    0.488244    0.499174   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      1.000000    0.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "75%      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "             Q398        Q399        Q400  \n",
       "count  681.000000  681.000000  681.000000  \n",
       "mean     0.475771    0.248164    0.283407  \n",
       "std      0.499780    0.432265    0.450983  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000  \n",
       "75%      1.000000    0.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 400 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty columns  Index(['Q74', 'Q76', 'Q78', 'Q80', 'Q82', 'Q84', 'Q86', 'Q88', 'Q90', 'Q92',\n",
      "       'Q94', 'Q96', 'Q100', 'Q101', 'Q102'],\n",
      "      dtype='object')\n",
      "Only one different value columns  ['Q74', 'Q76', 'Q78', 'Q80', 'Q82', 'Q84', 'Q86', 'Q88', 'Q90', 'Q92', 'Q94', 'Q96', 'Q100', 'Q101', 'Q102', 'Q131', 'Q133', 'Q135', 'Q137', 'Q152', 'Q154', 'Q156', 'Q158', 'Q176', 'Q178', 'Q180', 'Q182', 'Q197', 'Q199', 'Q201', 'Q203', 'Q210', 'Q212', 'Q218', 'Q220', 'Q222', 'Q224', 'Q349', 'Q350', 'Q352', 'Q353', 'Q355', 'Q356', 'Q358', 'Q359', 'Q362', 'Q365', 'Q368', 'Q371']\n",
      "Int value params ['Q10', 'Q19', 'Q49', 'Q50', 'Q51', 'Q103', 'Q104', 'Q105', 'Q106', 'Q107', 'Q108', 'Q114', 'Q115', 'Q116', 'Q160', 'Q161', 'Q162']\n"
     ]
    }
   ],
   "source": [
    "display(dataset.describe())\n",
    "# Remove 'Label' from values as data is going to be splited\n",
    "int_value_params.remove('Label')\n",
    "print(\"Empty columns \", null_columns)\n",
    "print(\"Only one different value columns \", one_value_params)\n",
    "print(\"Int value params\", int_value_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a first look to parameters list we could deduce: \n",
    "- Most of parameters, apart from label and the ones described below, have bool values\n",
    "- Parameters ['Q74', 'Q76', 'Q78', 'Q80', 'Q82', 'Q84', 'Q86', 'Q88', 'Q90', 'Q92', 'Q94', 'Q96', 'Q100', 'Q101', 'Q102', 'Q131', 'Q133', 'Q135', 'Q137', 'Q152', 'Q154', 'Q156', 'Q158', 'Q176', 'Q178', 'Q180', 'Q182', 'Q197', 'Q199', 'Q201', 'Q203', 'Q210', 'Q212', 'Q218', 'Q220', 'Q222', 'Q224', 'Q349', 'Q350', 'Q352', 'Q353', 'Q355', 'Q356', 'Q358', 'Q359', 'Q362', 'Q365', 'Q368', 'Q371'] have only one different value so probably they are good candidates for being removed from dataset without impact in results\n",
    "- Parameters ['Q74', 'Q76', 'Q78', 'Q80', 'Q82', 'Q84', 'Q86', 'Q88', 'Q90', 'Q92','Q94', 'Q96', 'Q100', 'Q101', 'Q102'] have no value at all, so we can delete them\n",
    "- Parameter ['Q10', 'Q19', 'Q49', 'Q50', 'Q51', 'Q103', 'Q104', 'Q105', 'Q106', 'Q107', 'Q108', 'Q114', 'Q115', 'Q116', 'Q160', 'Q161', 'Q162'] of int type are susceptible for regularizarion later\n",
    "\n",
    "There is no need for on hot encoding as there are not string params. We'll perform it later with label dataset in the prediction section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see graphically which is the disease distribution inside dataset.\n",
    "\n",
    ">**Note:** Given that we are dealing with almost 400 features, it's been almost impossible to gen a graphical representation on feateres, telations between them, heat map. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target label\n",
    "diagnosis_raw = dataset['Label']\n",
    "features_raw = dataset.drop('Label', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets remove empty columns and the apply log transform to numerical values to ensure all values are in range [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q10', 'Q19', 'Q49', 'Q50', 'Q51', 'Q103', 'Q104', 'Q105', 'Q106', 'Q107', 'Q108', 'Q114', 'Q115', 'Q116', 'Q160', 'Q161', 'Q162']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q391</th>\n",
       "      <th>Q392</th>\n",
       "      <th>Q393</th>\n",
       "      <th>Q394</th>\n",
       "      <th>Q395</th>\n",
       "      <th>Q396</th>\n",
       "      <th>Q397</th>\n",
       "      <th>Q398</th>\n",
       "      <th>Q399</th>\n",
       "      <th>Q400</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.370143</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.928789</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.584963</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.732021</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.841958</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9       Q10  ...   Q391  Q392  Q393  Q394  \\\n",
       "0   1   1   0   1   0   1   1   0   1  0.370143  ...      1     0     0     1   \n",
       "1   1   0   1   1   1   1   1   1   1  0.928789  ...      0     1     0     1   \n",
       "2   0   0   0   0   0   0   0   1   0  0.584963  ...      1     1     1     1   \n",
       "3   0   0   0   1   0   0   0   0   1  0.732021  ...      1     1     0     1   \n",
       "4   1   0   0   0   1   1   0   0   0  0.841958  ...      0     1     0     0   \n",
       "\n",
       "   Q395  Q396  Q397  Q398  Q399  Q400  \n",
       "0     0     1     0     1     0     0  \n",
       "1     0     1     0     1     0     0  \n",
       "2     1     0     1     0     0     0  \n",
       "3     0     1     1     1     0     0  \n",
       "4     1     1     1     0     0     1  \n",
       "\n",
       "[5 rows x 385 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_raw = features_raw.drop(null_columns, axis=1)\n",
    "features_raw.head(10)\n",
    "print(int_value_params)\n",
    "features_log_transformed = pd.DataFrame(data = features_raw)\n",
    "features_log_transformed[int_value_params] = features_raw[int_value_params].apply(lambda x: np.log(x + 1))\n",
    "\n",
    "scaler = MinMaxScaler() # default=(0, 1)\n",
    "\n",
    "features_log_minmax_transform = pd.DataFrame(data = features_log_transformed)\n",
    "features_log_minmax_transform[int_value_params] = scaler.fit_transform(features_log_transformed[int_value_params])\n",
    "\n",
    "display(features_log_minmax_transform.head(n = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning\n",
    "One of the goals of the project is to propose to remove those questions that has no impact on patient diagnosis. We could achieve this by using feature relevance. The coefficient of determination, R^2, is scored between 0 and 1, with 1 being a perfect fit. A negative R^2 implies the model fails to fit the data. If you get a low score for a particular feature, that lends us to beleive that that feature point is hard to predict using the other features, thereby making it an important feature to consider when considering relevance.\n",
    "\n",
    "I have tried to predict 'Frozen' customer expending. The prediction score is -0.21013589012491396. As a negative value, it means the regressor failed to predict the value of the column based on the rest of the features. This suggests that the 'Frozen' feature is relevant to identify customer's spending habits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q119 1.0\n",
      "Q121 1.0\n",
      "Q123 1.0\n",
      "Q125 1.0\n",
      "Q127 1.0\n",
      "Q129 1.0\n",
      "Q131 1.0\n",
      "Q133 1.0\n",
      "Q135 1.0\n",
      "Q137 1.0\n",
      "Q140 1.0\n",
      "Q142 1.0\n",
      "Q144 1.0\n",
      "Q146 1.0\n",
      "Q148 1.0\n",
      "Q152 1.0\n",
      "Q154 1.0\n",
      "Q156 1.0\n",
      "Q158 1.0\n",
      "Q172 0.9656641604010024\n",
      "Q176 1.0\n",
      "Q178 1.0\n",
      "Q180 1.0\n",
      "Q182 1.0\n",
      "Q193 0.931328320802005\n",
      "Q197 1.0\n",
      "Q199 1.0\n",
      "Q201 1.0\n",
      "Q203 1.0\n",
      "Q208 0.92175899486008\n",
      "Q210 1.0\n",
      "Q212 1.0\n",
      "Q216 0.908869179600887\n",
      "Q218 1.0\n",
      "Q220 1.0\n",
      "Q222 1.0\n",
      "Q224 1.0\n",
      "Q286 0.9150124069478908\n",
      "Q296 1.0\n",
      "Q300 1.0\n",
      "Q304 1.0\n",
      "Q307 0.9093915343915344\n",
      "Q308 1.0\n",
      "Q312 1.0\n",
      "Q316 1.0\n",
      "Q320 1.0\n",
      "Q323 1.0\n",
      "Q325 1.0\n",
      "Q326 1.0\n",
      "Q329 1.0\n",
      "Q332 1.0\n",
      "Q335 1.0\n",
      "Q337 1.0\n",
      "Q340 1.0\n",
      "Q343 1.0\n",
      "Q346 1.0\n",
      "Q349 1.0\n",
      "Q350 1.0\n",
      "Q352 1.0\n",
      "Q353 1.0\n",
      "Q355 1.0\n",
      "Q356 1.0\n",
      "Q358 1.0\n",
      "Q359 1.0\n",
      "Q362 1.0\n",
      "Q365 1.0\n",
      "Q368 1.0\n",
      "Q371 1.0\n"
     ]
    }
   ],
   "source": [
    "dataset = features_log_minmax_transform\n",
    "\n",
    "for i in range(0, len(dataset.columns)) :\n",
    "    new_data = dataset.drop(dataset.columns[i], axis = 1)\n",
    "\n",
    "    # Split the data into training and testing sets(0.2) using the given feature as the target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(new_data, dataset[dataset.columns[i]], test_size=0.2, random_state = 42)\n",
    "\n",
    "    # Fitting training set with decision tree regressor \n",
    "    regressor = DecisionTreeRegressor(random_state = 42)\n",
    "    regressor.fit(X_train,y_train)\n",
    "\n",
    "    # Get the score of the prediction using the testing set\n",
    "    score = regressor.score(X_test,y_test)\n",
    "    # Get values of R^2 score above 0.5\n",
    "    if score > 0.9 :\n",
    "        print(dataset.columns[i], score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(dataset, hue='Label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers in this situation al only reltives to numerical as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers detected in more than one feature\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "# For each feature find the data points with extreme high or low values\n",
    "# List to store outliers detected in loop\n",
    "all_outliers = []\n",
    "for feature in int_value_params :\n",
    "    \n",
    "    # TODO: Calculate Q1 (25th percentile of the data) for the given feature\n",
    "    Q1 = np.percentile(dataset[feature], 25)\n",
    "    \n",
    "    # TODO: Calculate Q3 (75th percentile of the data) for the given feature\n",
    "    Q3 = np.percentile(dataset[feature], 75)\n",
    "    \n",
    "    # TODO: Use the interquartile range to calculate an outlier step (1.5 times the interquartile range)\n",
    "    step = (Q3 - Q1)*1.5\n",
    "    \n",
    "    # Display the outliers\n",
    "    #print(\"Data points considered outliers for the feature '{}':\".format(feature))\n",
    "    feature_outliers = dataset[~((dataset[feature] >= Q1 - step) & (dataset[feature] <= Q3 + step))]\n",
    "    #display(feature_outliers)\n",
    "    \n",
    "    all_outliers.extend(feature_outliers.index.values)\n",
    "    \n",
    "# OPTIONAL: Select the indices for data points you wish to remove\n",
    "import collections\n",
    "outliers =  [item for item, count in collections.Counter(all_outliers).items() if count > 1]\n",
    "print('Outliers detected in more than one feature')\n",
    "print(len(outliers))\n",
    "\n",
    "# Remove the outliers, if any were specified\n",
    "good_data = dataset.drop(dataset.index[outliers]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality Reduction and Project Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Apply your clustering algorithm of choice to the reduced data \n",
    "\n",
    "def score_by_clusters(n) :\n",
    "    clusterer = GaussianMixture(n_components=n, random_state=42)\n",
    "    clusterer.fit(dataset)\n",
    "\n",
    "    # TODO: Predict the cluster for each data point\n",
    "    preds = clusterer.predict(dataset)\n",
    "\n",
    "    # TODO: Find the cluster centers\n",
    "    centers = clusterer.means_ \n",
    "\n",
    "    # TODO: Predict the cluster for each transformed sample data point\n",
    "    #sample_preds = clusterer.predict(pca_samples)\n",
    "\n",
    "    # TODO: Calculate the mean silhouette coefficient for the number of clusters chosen\n",
    "    score = silhouette_score(dataset, preds)\n",
    "    print(\"Silhouette Score for {} clusters: {}\".format(n, score))\n",
    "    return preds, centers, score\n",
    "    \n",
    "for i in range(2,12) : \n",
    "    score_by_clusters(i)\n",
    "#pca_samples = []\n",
    "#preds, centers, score = score_by_clusters(2)\n",
    "#vs.cluster_results(dataset, preds, centers, pca_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_clusters(X, n_clusters, rseed=2):\n",
    "    # 1. Randomly choose clusters\n",
    "    rng = np.random.RandomState(rseed)\n",
    "    i = rng.permutation(X.shape[0])[:n_clusters]\n",
    "    centers = X[i]\n",
    "    \n",
    "    while True:\n",
    "        # 2a. Assign labels based on closest center\n",
    "        labels = pairwise_distances_argmin(X, centers)\n",
    "        \n",
    "        # 2b. Find new centers from means of points\n",
    "        new_centers = np.array([X[labels == i].mean(0)\n",
    "                                for i in range(n_clusters)])\n",
    "        \n",
    "        # 2c. Check for convergence\n",
    "        if np.all(centers == new_centers):\n",
    "            break\n",
    "        centers = new_centers\n",
    "    \n",
    "    return centers, labels\n",
    "\n",
    "centers, labels = find_clusters(dataset, 4)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels,\n",
    "            s=50, cmap='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q391</th>\n",
       "      <th>Q392</th>\n",
       "      <th>Q393</th>\n",
       "      <th>Q394</th>\n",
       "      <th>Q395</th>\n",
       "      <th>Q396</th>\n",
       "      <th>Q397</th>\n",
       "      <th>Q398</th>\n",
       "      <th>Q399</th>\n",
       "      <th>Q400</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.370143</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.928789</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.584963</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.732021</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.841958</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.370143</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.584963</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.370143</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.584963</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9       Q10  ...   Q391  Q392  Q393  Q394  \\\n",
       "0   1   1   0   1   0   1   1   0   1  0.370143  ...      1     0     0     1   \n",
       "1   1   0   1   1   1   1   1   1   1  0.928789  ...      0     1     0     1   \n",
       "2   0   0   0   0   0   0   0   1   0  0.584963  ...      1     1     1     1   \n",
       "3   0   0   0   1   0   0   0   0   1  0.732021  ...      1     1     0     1   \n",
       "4   1   0   0   0   1   1   0   0   0  0.841958  ...      0     1     0     0   \n",
       "5   0   0   0   0   0   0   0   0   0  0.370143  ...      1     1     1     0   \n",
       "6   1   1   1   1   1   1   1   1   1  0.584963  ...      1     0     0     0   \n",
       "7   1   0   1   1   1   1   1   1   1  0.370143  ...      1     1     0     0   \n",
       "8   0   0   0   0   0   0   0   0   1  1.000000  ...      1     1     0     1   \n",
       "9   1   0   1   1   1   1   1   1   1  0.584963  ...      0     0     0     0   \n",
       "\n",
       "   Q395  Q396  Q397  Q398  Q399  Q400  \n",
       "0     0     1     0     1     0     0  \n",
       "1     0     1     0     1     0     0  \n",
       "2     1     0     1     0     0     0  \n",
       "3     0     1     1     1     0     0  \n",
       "4     1     1     1     0     0     1  \n",
       "5     0     0     1     1     0     0  \n",
       "6     1     1     1     0     0     0  \n",
       "7     1     1     1     0     0     1  \n",
       "8     1     0     0     1     1     0  \n",
       "9     0     1     0     1     0     1  \n",
       "\n",
       "[10 rows x 385 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Cefaleas/TMD\n",
       "1     DM. Referido\n",
       "2          DDSRSLA\n",
       "3          DDCRCBI\n",
       "4          DDSRCLA\n",
       "5             DDCR\n",
       "6          Mialgia\n",
       "7    Mialgia Local\n",
       "8             DDCR\n",
       "9        Artralgia\n",
       "Name: Label, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosis_raw.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to one hot encode diagnosis labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(diagnosis_raw)\n",
    "encoded_Y = encoder.transform(diagnosis_raw)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset, dummy_y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 4)                 1544      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 11)                55        \n",
      "=================================================================\n",
      "Total params: 1,619\n",
      "Trainable params: 1,619\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "classifier = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(4, activation='relu', kernel_initializer='random_normal', input_dim=385))\n",
    "#classifier.add(Dropout(0.2))\n",
    "#Second  Hidden Layer\n",
    "classifier.add(Dense(4, activation='relu', kernel_initializer='random_normal'))\n",
    "#classifier.add(Dropout(0.2))\n",
    "#Output Layer\n",
    "classifier.add(Dense(11, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "#classifier.add(Dropout(0.2))\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the neural network\n",
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "#classifier.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 318 samples, validate on 158 samples\n",
      "Epoch 1/150\n",
      "318/318 [==============================] - 0s 592us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0509 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.98504, saving model to saved_models/weights.best.hdf5\n",
      "Epoch 2/150\n",
      "318/318 [==============================] - 0s 526us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0545 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.98504\n",
      "Epoch 3/150\n",
      "318/318 [==============================] - 0s 619us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0549 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.98504\n",
      "Epoch 4/150\n",
      "318/318 [==============================] - 0s 640us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0565 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.98504\n",
      "Epoch 5/150\n",
      "318/318 [==============================] - 0s 642us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0515 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.98504\n",
      "Epoch 6/150\n",
      "318/318 [==============================] - 0s 523us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0557 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.98504\n",
      "Epoch 7/150\n",
      "318/318 [==============================] - 0s 688us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0586 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.98504\n",
      "Epoch 8/150\n",
      "318/318 [==============================] - 0s 515us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0558 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.98504\n",
      "Epoch 9/150\n",
      "318/318 [==============================] - 0s 762us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0560 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.98504\n",
      "Epoch 10/150\n",
      "318/318 [==============================] - 0s 729us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0574 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.98504\n",
      "Epoch 11/150\n",
      "318/318 [==============================] - 0s 727us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0579 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.98504\n",
      "Epoch 12/150\n",
      "318/318 [==============================] - 0s 750us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0551 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.98504\n",
      "Epoch 13/150\n",
      "318/318 [==============================] - 0s 807us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0507 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.98504\n",
      "Epoch 14/150\n",
      "318/318 [==============================] - 0s 885us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0562 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.98504\n",
      "Epoch 15/150\n",
      "318/318 [==============================] - 0s 838us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0595 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.98504\n",
      "Epoch 16/150\n",
      "318/318 [==============================] - 0s 748us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0614 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.98504\n",
      "Epoch 17/150\n",
      "318/318 [==============================] - 0s 746us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0579 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.98504\n",
      "Epoch 18/150\n",
      "318/318 [==============================] - 0s 822us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0589 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.98504\n",
      "Epoch 19/150\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 9.9555e-04 - acc: 1.0000 - val_loss: 0.0609 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.98504\n",
      "Epoch 20/150\n",
      "318/318 [==============================] - 0s 905us/step - loss: 9.8995e-04 - acc: 1.0000 - val_loss: 0.0621 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.98504\n",
      "Epoch 21/150\n",
      "318/318 [==============================] - 0s 708us/step - loss: 9.7603e-04 - acc: 1.0000 - val_loss: 0.0622 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.98504\n",
      "Epoch 22/150\n",
      "318/318 [==============================] - 0s 861us/step - loss: 9.7249e-04 - acc: 1.0000 - val_loss: 0.0629 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.98504\n",
      "Epoch 23/150\n",
      "318/318 [==============================] - 0s 750us/step - loss: 9.4453e-04 - acc: 1.0000 - val_loss: 0.0599 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.98504\n",
      "Epoch 24/150\n",
      "318/318 [==============================] - 0s 742us/step - loss: 9.3520e-04 - acc: 1.0000 - val_loss: 0.0616 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.98504\n",
      "Epoch 25/150\n",
      "318/318 [==============================] - 0s 693us/step - loss: 9.2255e-04 - acc: 1.0000 - val_loss: 0.0680 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.98504\n",
      "Epoch 26/150\n",
      "318/318 [==============================] - 0s 732us/step - loss: 9.0804e-04 - acc: 1.0000 - val_loss: 0.0610 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.98504\n",
      "Epoch 27/150\n",
      "318/318 [==============================] - 0s 713us/step - loss: 9.0526e-04 - acc: 1.0000 - val_loss: 0.0647 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.98504\n",
      "Epoch 28/150\n",
      "318/318 [==============================] - 0s 662us/step - loss: 8.8532e-04 - acc: 1.0000 - val_loss: 0.0662 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.98504\n",
      "Epoch 29/150\n",
      "318/318 [==============================] - 0s 736us/step - loss: 8.7202e-04 - acc: 1.0000 - val_loss: 0.0633 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.98504\n",
      "Epoch 30/150\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 8.5946e-04 - acc: 1.0000 - val_loss: 0.0667 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.98504\n",
      "Epoch 31/150\n",
      "318/318 [==============================] - 0s 826us/step - loss: 8.5361e-04 - acc: 1.0000 - val_loss: 0.0659 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.98504\n",
      "Epoch 32/150\n",
      "318/318 [==============================] - 0s 950us/step - loss: 8.4456e-04 - acc: 1.0000 - val_loss: 0.0640 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.98504\n",
      "Epoch 33/150\n",
      "318/318 [==============================] - 0s 926us/step - loss: 8.3221e-04 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.98504\n",
      "Epoch 34/150\n",
      "318/318 [==============================] - 0s 843us/step - loss: 8.2231e-04 - acc: 1.0000 - val_loss: 0.0696 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.98504\n",
      "Epoch 35/150\n",
      "318/318 [==============================] - 0s 794us/step - loss: 8.1142e-04 - acc: 1.0000 - val_loss: 0.0643 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.98504\n",
      "Epoch 36/150\n",
      "318/318 [==============================] - 0s 895us/step - loss: 7.9703e-04 - acc: 1.0000 - val_loss: 0.0680 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.98504\n",
      "Epoch 37/150\n",
      "318/318 [==============================] - 0s 902us/step - loss: 7.9098e-04 - acc: 1.0000 - val_loss: 0.0700 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.98504\n",
      "Epoch 38/150\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 7.8399e-04 - acc: 1.0000 - val_loss: 0.0620 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.98504\n",
      "Epoch 39/150\n",
      "318/318 [==============================] - 0s 932us/step - loss: 7.7141e-04 - acc: 1.0000 - val_loss: 0.0665 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.98504\n",
      "Epoch 40/150\n",
      "318/318 [==============================] - 0s 877us/step - loss: 7.5760e-04 - acc: 1.0000 - val_loss: 0.0685 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.98504\n",
      "Epoch 41/150\n",
      "318/318 [==============================] - 0s 820us/step - loss: 7.5811e-04 - acc: 1.0000 - val_loss: 0.0705 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.98504\n",
      "Epoch 42/150\n",
      "318/318 [==============================] - 0s 927us/step - loss: 7.3909e-04 - acc: 1.0000 - val_loss: 0.0706 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.98504\n",
      "Epoch 43/150\n",
      "318/318 [==============================] - 0s 840us/step - loss: 7.2629e-04 - acc: 1.0000 - val_loss: 0.0684 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.98504\n",
      "Epoch 44/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318/318 [==============================] - 0s 869us/step - loss: 7.1842e-04 - acc: 1.0000 - val_loss: 0.0699 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.98504\n",
      "Epoch 45/150\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 7.0875e-04 - acc: 1.0000 - val_loss: 0.0734 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.98504\n",
      "Epoch 46/150\n",
      "318/318 [==============================] - 0s 999us/step - loss: 7.0094e-04 - acc: 1.0000 - val_loss: 0.0697 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.98504\n",
      "Epoch 47/150\n",
      "318/318 [==============================] - 0s 941us/step - loss: 6.9401e-04 - acc: 1.0000 - val_loss: 0.0739 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.98504\n",
      "Epoch 48/150\n",
      "318/318 [==============================] - 0s 814us/step - loss: 6.8064e-04 - acc: 1.0000 - val_loss: 0.0777 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.98504\n",
      "Epoch 49/150\n",
      "318/318 [==============================] - 0s 729us/step - loss: 6.7579e-04 - acc: 1.0000 - val_loss: 0.0764 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.98504\n",
      "Epoch 50/150\n",
      "318/318 [==============================] - 0s 775us/step - loss: 6.6352e-04 - acc: 1.0000 - val_loss: 0.0758 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.98504\n",
      "Epoch 51/150\n",
      "318/318 [==============================] - 0s 938us/step - loss: 6.5284e-04 - acc: 1.0000 - val_loss: 0.0769 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.98504\n",
      "Epoch 52/150\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 6.5037e-04 - acc: 1.0000 - val_loss: 0.0755 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.98504\n",
      "Epoch 53/150\n",
      "318/318 [==============================] - 0s 910us/step - loss: 6.4368e-04 - acc: 1.0000 - val_loss: 0.0740 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.98504\n",
      "Epoch 54/150\n",
      "318/318 [==============================] - 0s 892us/step - loss: 6.2969e-04 - acc: 1.0000 - val_loss: 0.0747 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.98504\n",
      "Epoch 55/150\n",
      "318/318 [==============================] - 0s 905us/step - loss: 6.2332e-04 - acc: 1.0000 - val_loss: 0.0791 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.98504\n",
      "Epoch 56/150\n",
      "318/318 [==============================] - 0s 873us/step - loss: 6.1626e-04 - acc: 1.0000 - val_loss: 0.0808 - val_acc: 0.9816\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.98504\n",
      "Epoch 57/150\n",
      "318/318 [==============================] - 0s 939us/step - loss: 6.2133e-04 - acc: 1.0000 - val_loss: 0.0739 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.98504\n",
      "Epoch 58/150\n",
      "318/318 [==============================] - 0s 919us/step - loss: 6.0984e-04 - acc: 1.0000 - val_loss: 0.0777 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.98504\n",
      "Epoch 59/150\n",
      "318/318 [==============================] - 0s 974us/step - loss: 5.9208e-04 - acc: 1.0000 - val_loss: 0.0789 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.98504\n",
      "Epoch 60/150\n",
      "318/318 [==============================] - 0s 817us/step - loss: 5.7985e-04 - acc: 1.0000 - val_loss: 0.0829 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.98504\n",
      "Epoch 61/150\n",
      "318/318 [==============================] - 0s 834us/step - loss: 5.7606e-04 - acc: 1.0000 - val_loss: 0.0759 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.98504\n",
      "Epoch 62/150\n",
      "318/318 [==============================] - 0s 1ms/step - loss: 5.7304e-04 - acc: 1.0000 - val_loss: 0.0787 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.98504\n",
      "Epoch 63/150\n",
      "318/318 [==============================] - 0s 917us/step - loss: 5.6206e-04 - acc: 1.0000 - val_loss: 0.0817 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.98504\n",
      "Epoch 64/150\n",
      "318/318 [==============================] - 0s 692us/step - loss: 5.5460e-04 - acc: 1.0000 - val_loss: 0.0725 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.98504\n",
      "Epoch 65/150\n",
      "318/318 [==============================] - 0s 755us/step - loss: 5.5516e-04 - acc: 1.0000 - val_loss: 0.0791 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.98504\n",
      "Epoch 66/150\n",
      "318/318 [==============================] - 0s 812us/step - loss: 5.3935e-04 - acc: 1.0000 - val_loss: 0.0805 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.98504\n",
      "Epoch 67/150\n",
      "318/318 [==============================] - 0s 656us/step - loss: 5.3172e-04 - acc: 1.0000 - val_loss: 0.0826 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.98504\n",
      "Epoch 68/150\n",
      "318/318 [==============================] - 0s 994us/step - loss: 5.3062e-04 - acc: 1.0000 - val_loss: 0.0751 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.98504\n",
      "Epoch 69/150\n",
      "318/318 [==============================] - 0s 705us/step - loss: 5.2179e-04 - acc: 1.0000 - val_loss: 0.0802 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.98504\n",
      "Epoch 70/150\n",
      "318/318 [==============================] - 0s 957us/step - loss: 5.1643e-04 - acc: 1.0000 - val_loss: 0.0791 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.98504\n",
      "Epoch 71/150\n",
      "318/318 [==============================] - 0s 922us/step - loss: 5.1267e-04 - acc: 1.0000 - val_loss: 0.0801 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.98504\n",
      "Epoch 72/150\n",
      "318/318 [==============================] - 0s 929us/step - loss: 5.0540e-04 - acc: 1.0000 - val_loss: 0.0849 - val_acc: 0.9816\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.98504\n",
      "Epoch 73/150\n",
      "318/318 [==============================] - 0s 882us/step - loss: 4.9359e-04 - acc: 1.0000 - val_loss: 0.0858 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.98504\n",
      "Epoch 74/150\n",
      "318/318 [==============================] - 0s 878us/step - loss: 4.9179e-04 - acc: 1.0000 - val_loss: 0.0800 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.98504\n",
      "Epoch 75/150\n",
      "318/318 [==============================] - 0s 783us/step - loss: 4.8383e-04 - acc: 1.0000 - val_loss: 0.0832 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.98504\n",
      "Epoch 76/150\n",
      "318/318 [==============================] - 0s 753us/step - loss: 4.7729e-04 - acc: 1.0000 - val_loss: 0.0832 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.98504\n",
      "Epoch 77/150\n",
      "318/318 [==============================] - 0s 682us/step - loss: 4.7146e-04 - acc: 1.0000 - val_loss: 0.0868 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.98504\n",
      "Epoch 78/150\n",
      "318/318 [==============================] - 0s 703us/step - loss: 4.6600e-04 - acc: 1.0000 - val_loss: 0.0891 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.98504\n",
      "Epoch 79/150\n",
      "318/318 [==============================] - 0s 657us/step - loss: 4.5467e-04 - acc: 1.0000 - val_loss: 0.0872 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.98504\n",
      "Epoch 80/150\n",
      "318/318 [==============================] - 0s 646us/step - loss: 4.5204e-04 - acc: 1.0000 - val_loss: 0.0890 - val_acc: 0.9816\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.98504\n",
      "Epoch 81/150\n",
      "318/318 [==============================] - 0s 660us/step - loss: 4.4428e-04 - acc: 1.0000 - val_loss: 0.0906 - val_acc: 0.9816\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.98504\n",
      "Epoch 82/150\n",
      "318/318 [==============================] - 0s 662us/step - loss: 4.4189e-04 - acc: 1.0000 - val_loss: 0.0852 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.98504\n",
      "Epoch 83/150\n",
      "318/318 [==============================] - 0s 672us/step - loss: 4.3746e-04 - acc: 1.0000 - val_loss: 0.0849 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.98504\n",
      "Epoch 84/150\n",
      "318/318 [==============================] - 0s 652us/step - loss: 4.3077e-04 - acc: 1.0000 - val_loss: 0.0876 - val_acc: 0.9816\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.98504\n",
      "Epoch 85/150\n",
      "318/318 [==============================] - 0s 644us/step - loss: 4.2341e-04 - acc: 1.0000 - val_loss: 0.0907 - val_acc: 0.9816\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.98504\n",
      "Epoch 86/150\n",
      "318/318 [==============================] - 0s 662us/step - loss: 4.2215e-04 - acc: 1.0000 - val_loss: 0.0929 - val_acc: 0.9804\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.98504\n",
      "Epoch 87/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318/318 [==============================] - 0s 686us/step - loss: 4.1407e-04 - acc: 1.0000 - val_loss: 0.0841 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.98504\n",
      "Epoch 88/150\n",
      "318/318 [==============================] - 0s 676us/step - loss: 4.0907e-04 - acc: 1.0000 - val_loss: 0.0908 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.98504\n",
      "Epoch 89/150\n",
      "318/318 [==============================] - 0s 675us/step - loss: 4.0287e-04 - acc: 1.0000 - val_loss: 0.0904 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.98504\n",
      "Epoch 90/150\n",
      "318/318 [==============================] - 0s 716us/step - loss: 3.9942e-04 - acc: 1.0000 - val_loss: 0.0931 - val_acc: 0.9816\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.98504\n",
      "Epoch 91/150\n",
      "318/318 [==============================] - 0s 652us/step - loss: 3.9037e-04 - acc: 1.0000 - val_loss: 0.0937 - val_acc: 0.9816\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.98504\n",
      "Epoch 92/150\n",
      "318/318 [==============================] - 0s 632us/step - loss: 3.8828e-04 - acc: 1.0000 - val_loss: 0.0955 - val_acc: 0.9804\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.98504\n",
      "Epoch 93/150\n",
      "318/318 [==============================] - 0s 638us/step - loss: 3.8129e-04 - acc: 1.0000 - val_loss: 0.0951 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.98504\n",
      "Epoch 94/150\n",
      "318/318 [==============================] - 0s 604us/step - loss: 3.8136e-04 - acc: 1.0000 - val_loss: 0.0919 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.98504\n",
      "Epoch 95/150\n",
      "318/318 [==============================] - 0s 622us/step - loss: 3.7767e-04 - acc: 1.0000 - val_loss: 0.0960 - val_acc: 0.9816\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.98504\n",
      "Epoch 96/150\n",
      "318/318 [==============================] - 0s 623us/step - loss: 3.7094e-04 - acc: 1.0000 - val_loss: 0.0967 - val_acc: 0.9816\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.98504\n",
      "Epoch 97/150\n",
      "318/318 [==============================] - 0s 635us/step - loss: 3.6387e-04 - acc: 1.0000 - val_loss: 0.0990 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.98504\n",
      "Epoch 98/150\n",
      "318/318 [==============================] - 0s 665us/step - loss: 3.5722e-04 - acc: 1.0000 - val_loss: 0.1004 - val_acc: 0.9799\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.98504\n",
      "Epoch 99/150\n",
      "318/318 [==============================] - 0s 600us/step - loss: 3.5413e-04 - acc: 1.0000 - val_loss: 0.0988 - val_acc: 0.9799\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.98504\n",
      "Epoch 100/150\n",
      "318/318 [==============================] - 0s 611us/step - loss: 3.5170e-04 - acc: 1.0000 - val_loss: 0.0994 - val_acc: 0.9804\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.98504\n",
      "Epoch 101/150\n",
      "318/318 [==============================] - 0s 580us/step - loss: 3.4734e-04 - acc: 1.0000 - val_loss: 0.1000 - val_acc: 0.9804\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.98504\n",
      "Epoch 102/150\n",
      "318/318 [==============================] - 0s 576us/step - loss: 3.3839e-04 - acc: 1.0000 - val_loss: 0.1042 - val_acc: 0.9799\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.98504\n",
      "Epoch 103/150\n",
      "318/318 [==============================] - 0s 588us/step - loss: 3.3516e-04 - acc: 1.0000 - val_loss: 0.1002 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.98504\n",
      "Epoch 104/150\n",
      "318/318 [==============================] - 0s 607us/step - loss: 3.3257e-04 - acc: 1.0000 - val_loss: 0.0992 - val_acc: 0.9799\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.98504\n",
      "Epoch 105/150\n",
      "318/318 [==============================] - 0s 616us/step - loss: 3.2960e-04 - acc: 1.0000 - val_loss: 0.1025 - val_acc: 0.9804\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.98504\n",
      "Epoch 106/150\n",
      "318/318 [==============================] - 0s 620us/step - loss: 3.2422e-04 - acc: 1.0000 - val_loss: 0.1064 - val_acc: 0.9804\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.98504\n",
      "Epoch 107/150\n",
      "318/318 [==============================] - 0s 610us/step - loss: 3.2119e-04 - acc: 1.0000 - val_loss: 0.0940 - val_acc: 0.9804\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.98504\n",
      "Epoch 108/150\n",
      "318/318 [==============================] - 0s 642us/step - loss: 3.1950e-04 - acc: 1.0000 - val_loss: 0.1006 - val_acc: 0.9799\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.98504\n",
      "Epoch 109/150\n",
      "318/318 [==============================] - 0s 614us/step - loss: 3.1151e-04 - acc: 1.0000 - val_loss: 0.1027 - val_acc: 0.9804\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.98504\n",
      "Epoch 110/150\n",
      "318/318 [==============================] - 0s 608us/step - loss: 3.0852e-04 - acc: 1.0000 - val_loss: 0.1049 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.98504\n",
      "Epoch 111/150\n",
      "318/318 [==============================] - 0s 618us/step - loss: 3.0364e-04 - acc: 1.0000 - val_loss: 0.1085 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.98504\n",
      "Epoch 112/150\n",
      "318/318 [==============================] - 0s 624us/step - loss: 2.9960e-04 - acc: 1.0000 - val_loss: 0.1092 - val_acc: 0.9799\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.98504\n",
      "Epoch 113/150\n",
      "318/318 [==============================] - 0s 628us/step - loss: 2.9452e-04 - acc: 1.0000 - val_loss: 0.1117 - val_acc: 0.9804\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.98504\n",
      "Epoch 114/150\n",
      "318/318 [==============================] - 0s 634us/step - loss: 2.9505e-04 - acc: 1.0000 - val_loss: 0.1064 - val_acc: 0.9804\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.98504\n",
      "Epoch 115/150\n",
      "318/318 [==============================] - 0s 645us/step - loss: 2.8951e-04 - acc: 1.0000 - val_loss: 0.1056 - val_acc: 0.9799\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.98504\n",
      "Epoch 116/150\n",
      "318/318 [==============================] - 0s 593us/step - loss: 2.8715e-04 - acc: 1.0000 - val_loss: 0.1084 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.98504\n",
      "Epoch 117/150\n",
      "318/318 [==============================] - 0s 617us/step - loss: 2.8396e-04 - acc: 1.0000 - val_loss: 0.1078 - val_acc: 0.9799\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.98504\n",
      "Epoch 118/150\n",
      "318/318 [==============================] - 0s 627us/step - loss: 2.7815e-04 - acc: 1.0000 - val_loss: 0.1108 - val_acc: 0.9799\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.98504\n",
      "Epoch 119/150\n",
      "318/318 [==============================] - 0s 609us/step - loss: 2.7651e-04 - acc: 1.0000 - val_loss: 0.1008 - val_acc: 0.9804\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.98504\n",
      "Epoch 120/150\n",
      "318/318 [==============================] - 0s 621us/step - loss: 2.7346e-04 - acc: 1.0000 - val_loss: 0.1035 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.98504\n",
      "Epoch 121/150\n",
      "318/318 [==============================] - 0s 579us/step - loss: 2.6800e-04 - acc: 1.0000 - val_loss: 0.1058 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.98504\n",
      "Epoch 122/150\n",
      "318/318 [==============================] - 0s 622us/step - loss: 2.6668e-04 - acc: 1.0000 - val_loss: 0.1067 - val_acc: 0.9799\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.98504\n",
      "Epoch 123/150\n",
      "318/318 [==============================] - 0s 674us/step - loss: 2.6030e-04 - acc: 1.0000 - val_loss: 0.1093 - val_acc: 0.9804\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.98504\n",
      "Epoch 124/150\n",
      "318/318 [==============================] - 0s 612us/step - loss: 2.5699e-04 - acc: 1.0000 - val_loss: 0.1133 - val_acc: 0.9799\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.98504\n",
      "Epoch 125/150\n",
      "318/318 [==============================] - 0s 593us/step - loss: 2.5525e-04 - acc: 1.0000 - val_loss: 0.1149 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.98504\n",
      "Epoch 126/150\n",
      "318/318 [==============================] - 0s 567us/step - loss: 2.5270e-04 - acc: 1.0000 - val_loss: 0.1085 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.98504\n",
      "Epoch 127/150\n",
      "318/318 [==============================] - 0s 630us/step - loss: 2.4875e-04 - acc: 1.0000 - val_loss: 0.1104 - val_acc: 0.9804\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.98504\n",
      "Epoch 128/150\n",
      "318/318 [==============================] - 0s 639us/step - loss: 2.4536e-04 - acc: 1.0000 - val_loss: 0.1113 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.98504\n",
      "Epoch 129/150\n",
      "318/318 [==============================] - 0s 645us/step - loss: 2.4288e-04 - acc: 1.0000 - val_loss: 0.1148 - val_acc: 0.9799\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.98504\n",
      "Epoch 130/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318/318 [==============================] - 0s 631us/step - loss: 2.3852e-04 - acc: 1.0000 - val_loss: 0.1168 - val_acc: 0.9799\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.98504\n",
      "Epoch 131/150\n",
      "318/318 [==============================] - 0s 551us/step - loss: 2.3735e-04 - acc: 1.0000 - val_loss: 0.1070 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.98504\n",
      "Epoch 132/150\n",
      "318/318 [==============================] - 0s 561us/step - loss: 2.3668e-04 - acc: 1.0000 - val_loss: 0.1123 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.98504\n",
      "Epoch 133/150\n",
      "318/318 [==============================] - 0s 553us/step - loss: 2.3384e-04 - acc: 1.0000 - val_loss: 0.1128 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.98504\n",
      "Epoch 134/150\n",
      "318/318 [==============================] - 0s 617us/step - loss: 2.2775e-04 - acc: 1.0000 - val_loss: 0.1173 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.98504\n",
      "Epoch 135/150\n",
      "318/318 [==============================] - 0s 611us/step - loss: 2.2453e-04 - acc: 1.0000 - val_loss: 0.1165 - val_acc: 0.9799\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.98504\n",
      "Epoch 136/150\n",
      "318/318 [==============================] - 0s 592us/step - loss: 2.2204e-04 - acc: 1.0000 - val_loss: 0.1192 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.98504\n",
      "Epoch 137/150\n",
      "318/318 [==============================] - 0s 601us/step - loss: 2.2093e-04 - acc: 1.0000 - val_loss: 0.1082 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.98504\n",
      "Epoch 138/150\n",
      "318/318 [==============================] - 0s 603us/step - loss: 2.1742e-04 - acc: 1.0000 - val_loss: 0.1130 - val_acc: 0.9781\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.98504\n",
      "Epoch 139/150\n",
      "318/318 [==============================] - 0s 611us/step - loss: 2.1371e-04 - acc: 1.0000 - val_loss: 0.1154 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.98504\n",
      "Epoch 140/150\n",
      "318/318 [==============================] - 0s 620us/step - loss: 2.1124e-04 - acc: 1.0000 - val_loss: 0.1158 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.98504\n",
      "Epoch 141/150\n",
      "318/318 [==============================] - 0s 628us/step - loss: 2.0904e-04 - acc: 1.0000 - val_loss: 0.1184 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.98504\n",
      "Epoch 142/150\n",
      "318/318 [==============================] - 0s 574us/step - loss: 2.0575e-04 - acc: 1.0000 - val_loss: 0.1205 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.98504\n",
      "Epoch 143/150\n",
      "318/318 [==============================] - 0s 652us/step - loss: 2.0366e-04 - acc: 1.0000 - val_loss: 0.1236 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.98504\n",
      "Epoch 144/150\n",
      "318/318 [==============================] - 0s 609us/step - loss: 2.0019e-04 - acc: 1.0000 - val_loss: 0.1248 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.98504\n",
      "Epoch 145/150\n",
      "318/318 [==============================] - 0s 633us/step - loss: 1.9762e-04 - acc: 1.0000 - val_loss: 0.1199 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.98504\n",
      "Epoch 146/150\n",
      "318/318 [==============================] - 0s 642us/step - loss: 1.9573e-04 - acc: 1.0000 - val_loss: 0.1170 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.98504\n",
      "Epoch 147/150\n",
      "318/318 [==============================] - 0s 564us/step - loss: 1.9291e-04 - acc: 1.0000 - val_loss: 0.1221 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.98504\n",
      "Epoch 148/150\n",
      "318/318 [==============================] - 0s 577us/step - loss: 1.8986e-04 - acc: 1.0000 - val_loss: 0.1224 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.98504\n",
      "Epoch 149/150\n",
      "318/318 [==============================] - 0s 596us/step - loss: 1.8859e-04 - acc: 1.0000 - val_loss: 0.1257 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.98504\n",
      "Epoch 150/150\n",
      "318/318 [==============================] - 0s 614us/step - loss: 1.8597e-04 - acc: 1.0000 - val_loss: 0.1267 - val_acc: 0.9781\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.98504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3c33e668>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "#checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', verbose=1, save_best_only=True)\n",
    "#classifier.fit(X_train, y_train,epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)\n",
    "#filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "filepath=\"saved_models/weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "classifier.fit(X_train, y_train, validation_split=0.33, epochs=epochs, batch_size=10, callbacks=callbacks_list, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the data to the training dataset\n",
    "X_train.head(10)\n",
    "classifier.fit(X_train,y_train, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476/476 [==============================] - 0s 51us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04218841201974032, 0.9927425494714945]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model=classifier.evaluate(X_train, y_train)\n",
    "eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_tensors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-077c3058a9f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saved_models/weights.best.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# get index of predicted dog breed for each image in test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdog_breed_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_tensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# report test accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_tensors' is not defined"
     ]
    }
   ],
   "source": [
    "classifier.load_weights('saved_models/weights.best.hdf5')\n",
    "# get index of predicted dog breed for each image in test set\n",
    "dog_breed_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(dog_breed_predictions)==np.argmax(test_targets, axis=1))/len(dog_breed_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model with reduced data\n",
    "\n",
    "We are going, to eliminate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement a prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Write a function that takes a path to an image as input\n",
    "### and returns the dog breed that is predicted by the model.\n",
    "def breed_predict(img_path):\n",
    "    # Extract the bottleneck features for Resnet CNN model\n",
    "    bottleneck_feature = extract_Xception(path_to_tensor(img_path))\n",
    "   \n",
    "    #Load the best model\n",
    "    xception_model.load_weights('saved_models/weights.best.exception.hdf5')\n",
    "    # obtain predicted vector\n",
    "    predicted_vector = xception_model.predict(bottleneck_feature)\n",
    "    # return dog breed that is predicted by the model\n",
    "    return dog_names[np.argmax(predicted_vector)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
